name: "Publisher (GitHub Pages)"
description: "Publishes security scan results as static HTML pages to GitHub Pages"
inputs:
  # What to publish
  outdir:
    description: "Directory containing scan outputs (JSON/MD/etc.)"
    required: true

  # Metadata
  metadata_timestamp:
    description: "Timestamp of the scan"
    required: true
  metadata_branch:
    description: "Branch name"
    required: false
    default: ""
  metadata_repository:
    description: "Repository name (owner/repo)"
    required: false
    default: ""
  metadata_commit_sha:
    description: "Commit SHA"
    required: false
    default: ""
  metadata_image_name:
    description: "Docker image name"
    required: false
    default: ""
  metadata_scan_id:
    description: "Scan run ID"
    required: false
    default: ""

  # Footer metadata
  app_docs_url:
    description: "URL to application documentation"
    required: false
    default: ""
  app_issues_url:
    description: "URL to application issue tracker"
    required: false
    default: ""
  ci_job_name:
    description: "CI job name (e.g., 'security-scan')"
    required: false
    default: ""
  ci_job_url:
    description: "URL to CI job run"
    required: false
    default: ""
  trivy_version:
    description: "Trivy version"
    required: false
    default: ""
  semgrep_version:
    description: "Semgrep version"
    required: false
    default: ""
  toolkit_version:
    description: "gh-security-toolkit version"
    required: false
    default: ""

  # Pages configuration
  channel:
    description: "Channel name for organizing scans (e.g., 'nightly-master', 'pr-123')"
    required: true
  pages_root:
    description: "Root directory for GitHub Pages (e.g., 'docs')"
    required: false
    default: "docs"
  retention_keep:
    description: "Keep at most N scans per channel (0=unlimited)"
    required: false
    default: "50"

runs:
  using: "composite"
  steps:
    - name: Check GitHub Pages visibility
      shell: bash
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        set -euo pipefail

        echo "üîç Checking GitHub Pages visibility..."

        # Query GitHub Pages configuration (single API call)
        echo "üì° DEBUG: Querying GitHub API for Pages configuration..."
        FULL_RESPONSE=$(gh api \
          -H "Accept: application/vnd.github+json" \
          -H "X-GitHub-Api-Version: 2022-11-28" \
          "/repos/${{ github.repository }}/pages" 2>&1) || FULL_RESPONSE=""

        echo "üì¶ DEBUG: Full API response:"
        echo "$FULL_RESPONSE"
        echo ""

        # Extract .public field from response (handle null vs false properly)
        if [ -n "$FULL_RESPONSE" ]; then
          IS_PUBLIC=$(echo "$FULL_RESPONSE" | jq -r 'if .public == null then "unknown" else (.public | tostring) end' 2>/dev/null) || IS_PUBLIC="unknown"
        else
          IS_PUBLIC="unknown"
        fi

        echo "üîé DEBUG: Extracted .public value: '$IS_PUBLIC'"
        echo ""

        if [ "$IS_PUBLIC" = "true" ]; then
          echo ""
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          echo "‚ùå ERROR: GitHub Pages is configured as PUBLIC"
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          echo ""
          echo "Security scan results MUST NOT be published to a public Pages site."
          echo ""
          echo "To fix this:"
          echo "  1. Go to: Settings ‚Üí Pages"
          echo "  2. Under 'Visibility', select 'Private'"
          echo "  3. Click 'Save'"
          echo ""
          echo "Note: Private Pages requires GitHub Enterprise Cloud."
          echo "      If not available, use 'publish_to: github-release' instead."
          echo ""
          echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
          exit 1
        elif [ "$IS_PUBLIC" = "false" ]; then
          echo "‚úÖ GitHub Pages is configured as Private - proceeding with deployment"
        elif [ "$IS_PUBLIC" = "null" ] || [ "$IS_PUBLIC" = "unknown" ]; then
          echo "‚ö†Ô∏è  Warning: Could not query GitHub Pages configuration."
          echo "   Pages may not be enabled yet, or visibility setting is not available."
          echo "   Proceeding with deployment."
          echo ""
          echo "   ‚ö†Ô∏è  IMPORTANT: After first deployment, verify in Settings ‚Üí Pages that:"
          echo "      ‚Ä¢ Pages is enabled and deployed from 'gh-pages' branch"
          echo "      ‚Ä¢ Visibility is set to 'Private' (requires GitHub Enterprise Cloud)"
          echo "      ‚Ä¢ If Private Pages is not available, use 'publish_to: github-release' instead"
        else
          echo "‚ö†Ô∏è  Warning: Unexpected visibility value: $IS_PUBLIC"
          echo "   Proceeding with deployment, but please verify Pages configuration."
        fi

    - name: Setup JBang
      uses: jbangdev/setup-jbang@main

    - name: Create metadata JSON
      id: metadata
      shell: bash
      run: |
        set -euo pipefail
        META_FILE="${{ inputs.outdir }}/scan-metadata.json"
        jq -n \
          --arg ts "${{ inputs.metadata_timestamp }}" \
          --arg branch "${{ inputs.metadata_branch }}" \
          --arg repo "${{ inputs.metadata_repository }}" \
          --arg sha "${{ inputs.metadata_commit_sha }}" \
          --arg image "${{ inputs.metadata_image_name }}" \
          --arg scan_id "${{ inputs.metadata_scan_id }}" \
          --arg app_docs_url "${{ inputs.app_docs_url }}" \
          --arg app_issues_url "${{ inputs.app_issues_url }}" \
          --arg ci_job_name "${{ inputs.ci_job_name }}" \
          --arg ci_job_url "${{ inputs.ci_job_url }}" \
          --arg trivy_version "${{ inputs.trivy_version }}" \
          --arg semgrep_version "${{ inputs.semgrep_version }}" \
          --arg toolkit_version "${{ inputs.toolkit_version }}" \
          '{
            timestamp: $ts,
            branch: $branch,
            repository: $repo,
            commit_sha: $sha,
            image_name: $image,
            scan_run_id: $scan_id,
            footer: {
              app_docs_url: $app_docs_url,
              app_issues_url: $app_issues_url,
              ci_job_name: $ci_job_name,
              ci_job_url: $ci_job_url,
              trivy_version: $trivy_version,
              semgrep_version: $semgrep_version,
              toolkit_version: $toolkit_version
            }
          }' > "$META_FILE"
        echo "meta_json=$META_FILE" >> "$GITHUB_OUTPUT"

    - name: Fetch existing GitHub Pages content
      shell: bash
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        set -euo pipefail

        echo "üì• Fetching existing GitHub Pages content..."

        # Get Pages URL from API response
        PAGES_URL=$(gh api \
          -H "Accept: application/vnd.github+json" \
          -H "X-GitHub-Api-Version: 2022-11-28" \
          "/repos/${{ github.repository }}/pages" \
          --jq '.html_url' 2>/dev/null) || PAGES_URL=""

        PAGES_ROOT="${{ inputs.pages_root }}"
        CHANNEL="${{ inputs.channel }}"

        if [ -z "$PAGES_URL" ] || [ "$PAGES_URL" = "null" ]; then
          echo "   ‚ÑπÔ∏è  No existing Pages site found - starting fresh"
          mkdir -p "$PAGES_ROOT/scans/$CHANNEL"
          exit 0
        fi

        echo "   Found Pages URL: $PAGES_URL"

        # Download existing channel scans metadata
        CHANNEL_URL="$PAGES_URL/scans/$CHANNEL"
        echo "   Checking for existing scans at: $CHANNEL_URL"

        mkdir -p "$PAGES_ROOT/scans/$CHANNEL"

        # Try to fetch existing scan list by checking channel index
        if curl -f -s -L "$CHANNEL_URL/" -o /dev/null 2>/dev/null; then
          echo "   üì¶ Downloading existing scans from channel: $CHANNEL"

          # Download channel directory listing (we'll parse scan timestamps from HTML)
          CHANNEL_HTML=$(curl -f -s -L "$CHANNEL_URL/" 2>/dev/null || echo "")

          if [ -n "$CHANNEL_HTML" ]; then
            # Extract scan timestamps from HTML links (format: YYYY-MM-DD-HHMMSS+ZZZZ)
            SCAN_DIRS=$(echo "$CHANNEL_HTML" | grep -oP 'href="[0-9]{4}-[0-9]{2}-[0-9]{2}-[0-9]{6}\+[0-9]{4}/"' | sed 's/href="//;s/\/"$//' | sort -r || echo "")

            if [ -n "$SCAN_DIRS" ]; then
              echo "   Found existing scans:"
              echo "$SCAN_DIRS" | head -5

              # Download each existing scan
              while IFS= read -r scan_ts; do
                if [ -n "$scan_ts" ]; then
                  SCAN_URL="$CHANNEL_URL/$scan_ts"
                  SCAN_DIR="$PAGES_ROOT/scans/$CHANNEL/$scan_ts"
                  mkdir -p "$SCAN_DIR"

                  # Download scan metadata and results
                  for file in scan-metadata.json index.html trivy-fs-results.json trivy-image-results.json semgrep-results.json; do
                    if curl -f -s -L "$SCAN_URL/$file" -o "$SCAN_DIR/$file" 2>/dev/null; then
                      echo "      ‚úì $scan_ts/$file"
                    fi
                  done
                fi
              done <<< "$SCAN_DIRS"
            else
              echo "   ‚ÑπÔ∏è  No existing scans found in channel"
            fi
          fi
        else
          echo "   ‚ÑπÔ∏è  Channel not found - starting fresh"
        fi

        # Also download global assets if they exist
        for file in style.css index.html; do
          if curl -f -s -L "$PAGES_URL/$file" -o "$PAGES_ROOT/$file" 2>/dev/null; then
            echo "   ‚úì Downloaded global $file"
          fi
        done

    - name: Apply retention policy
      if: ${{ inputs.retention_keep != '0' }}
      shell: bash
      run: |
        set -euo pipefail

        CHANNEL="${{ inputs.channel }}"
        KEEP="${{ inputs.retention_keep }}"
        PAGES_ROOT="${{ inputs.pages_root }}"
        CHANNEL_PATH="$PAGES_ROOT/scans/$CHANNEL"
        NEW_SCAN="${{ inputs.metadata_timestamp }}"

        echo "üßπ Applying retention policy for channel: $CHANNEL (keep=$KEEP)"

        if [ ! -d "$CHANNEL_PATH" ]; then
          echo "   ‚è≠Ô∏è  No existing scans - retention not needed"
          exit 0
        fi

        # List all scan directories including the new one we're about to add
        mapfile -t scans < <(find "$CHANNEL_PATH" -mindepth 1 -maxdepth 1 -type d -printf '%f\n' | sort -r)

        # Add new scan to the list for retention calculation
        scans=("$NEW_SCAN" "${scans[@]}")

        # Remove duplicates and sort
        mapfile -t scans < <(printf '%s\n' "${scans[@]}" | sort -u -r)

        total=${#scans[@]}
        echo "   Total scans (including new): $total"
        echo "   Retention limit: $KEEP"

        if [ "$total" -le "$KEEP" ]; then
          echo "   ‚úÖ No cleanup needed (total=$total, keep=$KEEP)"
          exit 0
        fi

        # Delete old scans beyond retention limit
        deleted=0
        for ((i=KEEP; i<total; i++)); do
          scan="${scans[$i]}"
          if [ "$scan" != "$NEW_SCAN" ] && [ -d "$CHANNEL_PATH/$scan" ]; then
            echo "   üóëÔ∏è  Deleting old scan: $scan"
            rm -rf "$CHANNEL_PATH/$scan"
            deleted=$((deleted + 1))
          fi
        done

        echo "   ‚úÖ Deleted $deleted old scans, keeping $KEEP newest"

    - name: Build GitHub Pages
      shell: bash
      run: |
        set -euo pipefail

        echo "üèóÔ∏è  Building GitHub Pages (incremental update)..."

        jbang "${{ github.action_path }}/../../../scripts/github_pages_builder.java" \
          "${{ inputs.outdir }}" \
          "${{ inputs.pages_root }}" \
          "${{ inputs.metadata_timestamp }}" \
          "${{ inputs.channel }}" \
          "${{ steps.metadata.outputs.meta_json }}"

    - name: Setup Pages
      uses: actions/configure-pages@v5

    - name: Upload Pages artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: ${{ inputs.pages_root }}

    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4

outputs:
  pages_url:
    description: "URL to the deployed GitHub Pages site"
    value: ${{ steps.deployment.outputs.page_url }}
